{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_tokenization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQlIRefaQFqeXS4SgitOXd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyg9C1usDQdN","executionInfo":{"status":"ok","timestamp":1655073304973,"user_tz":240,"elapsed":20142,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"883ea34f-e61f-4d46-8220-c7bfa656b6a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (185.125.190.39)] [Connecting to ppa.laun\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"metadata":{"id":"FGbOHjztDZyD","executionInfo":{"status":"ok","timestamp":1655073317726,"user_tz":240,"elapsed":7240,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"z_-3jfJWDoXo","executionInfo":{"status":"ok","timestamp":1655073320269,"user_tz":240,"elapsed":417,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create sample dataframe\n","dataframe = spark.createDataFrame([\n","                                   (0, \"Spark is great\"),\n","                                   (1, \"We are learning spark\"),\n","                                   (2, \"Spark is better than Hadoop no doubt\")               \n","], [\"id\", \"sentence\"])\n","\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBbo1kmrDqo4","executionInfo":{"status":"ok","timestamp":1655073694347,"user_tz":240,"elapsed":418,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"589626c6-619f-429f-d315-61bee01c7613"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning s...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgzMsj0YEDzh","executionInfo":{"status":"ok","timestamp":1655073699146,"user_tz":240,"elapsed":212,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"abcf02d3-9e90-42b4-a7fc-f34dab076998"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_8f6c660d27f7"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Transform and show dataframe\n","tokenized_DF = tokenizer.transform(dataframe)\n","tokenized_DF.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KrTKauDEScM","executionInfo":{"status":"ok","timestamp":1655073702326,"user_tz":240,"elapsed":954,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"88a04f40-e735-459c-b2d4-125905208f00"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"metadata":{"id":"HdHFbMnlEiao","executionInfo":{"status":"ok","timestamp":1655073785880,"user_tz":240,"elapsed":216,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"QI2Revj2FcXz","executionInfo":{"status":"ok","timestamp":1655073805623,"user_tz":240,"elapsed":142,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"R1l8e6IUFhN6","executionInfo":{"status":"ok","timestamp":1655073823309,"user_tz":240,"elapsed":164,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Create our tokenizer\n","tokenizer = Tokenizer(inputCol = \"sentence\", outputCol=\"words\")\n","\n","# Transform dataframe\n","tokenized_df = tokenizer.transform(dataframe)\n","\n","# Select the needed columns and don't truncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gECpGyjDFlgr","executionInfo":{"status":"ok","timestamp":1655074035838,"user_tz":240,"elapsed":1073,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"ac20fc9e-1c1c-4aca-f8b8-12cbdc36c867"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lHq3zJr7GV9c"},"execution_count":null,"outputs":[]}]}