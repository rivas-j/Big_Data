{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Stop_Words.ipynb","provenance":[],"authorship_tag":"ABX9TyMRriZ7JNNGQdJBnhHaO15j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUzPPxS_Guqf","executionInfo":{"status":"ok","timestamp":1655074210487,"user_tz":240,"elapsed":31376,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"fca47cc0-e72b-4c23-9993-c2fd9f18d186"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [806 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,992 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,515 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,830 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [982 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,290 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,262 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,015 kB]\n","Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n","Fetched 16.1 MB in 7s (2,272 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()\n"]},{"cell_type":"code","source":[" # Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"metadata":{"id":"wFKzvkvWG7b4","executionInfo":{"status":"ok","timestamp":1655074223382,"user_tz":240,"elapsed":12912,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Create dataframe\n","sentenceData = spark.createDataFrame([\n","                                      (0, [\"Big\", \"data\", \"is\", \"super\", \"powerful\"]),\n","                                      (1, [\"This\",\"is\",\"going\",\"to\",\"be\",\"epic\"])\n","], [\"id\", \"raw\"])\n","\n","sentenceData.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEbNYqBaG_-9","executionInfo":{"status":"ok","timestamp":1655074346924,"user_tz":240,"elapsed":3738,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"d9a6b056-f186-41ba-ddfc-3793b729759c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+\n","|id |raw                             |\n","+---+--------------------------------+\n","|0  |[Big, data, is, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |\n","+---+--------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover"],"metadata":{"id":"9lr2swvzHequ","executionInfo":{"status":"ok","timestamp":1655074357970,"user_tz":240,"elapsed":462,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Run the Remover\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"metadata":{"id":"WzsLsD4pHoAH","executionInfo":{"status":"ok","timestamp":1655074367019,"user_tz":240,"elapsed":429,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Transform and show data\n","remover.transform(sentenceData).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZeziYFopHqN6","executionInfo":{"status":"ok","timestamp":1655074399127,"user_tz":240,"elapsed":1241,"user":{"displayName":"Jonathan Rivas","userId":"02221449633171445441"}},"outputId":"c02ef707-0a9a-4b8e-c9b1-306dc75c612d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"4NrFERFVHx17"},"execution_count":null,"outputs":[]}]}